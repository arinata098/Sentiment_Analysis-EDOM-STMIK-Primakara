{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import some libraries\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style = 'whitegrid')\n",
    "import statistics\n",
    "\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, cross_validate\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, Dropout, LSTM\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_komentar</th>\n",
       "      <th>sentimen</th>\n",
       "      <th>komentar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1229</td>\n",
       "      <td>negative</td>\n",
       "      <td>kurang memberikan kegunaan dari materi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1562</td>\n",
       "      <td>negative</td>\n",
       "      <td>terlalu tegas dengan kontrak kuliah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>259</td>\n",
       "      <td>negative</td>\n",
       "      <td>harus lebih ontime ya pak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2084</td>\n",
       "      <td>positive</td>\n",
       "      <td>dalam pemaparan materi dan berdiskusi saya sud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2674</td>\n",
       "      <td>positive</td>\n",
       "      <td>mampu menggunakan kasus yang terjadi pada kehi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3553</th>\n",
       "      <td>3225</td>\n",
       "      <td>negative</td>\n",
       "      <td>kurang kurangin tugas yang buat kringet dingin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3554</th>\n",
       "      <td>980</td>\n",
       "      <td>negative</td>\n",
       "      <td>terlalu banyak tambahan bobot mata kuliah yang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3555</th>\n",
       "      <td>214</td>\n",
       "      <td>negative</td>\n",
       "      <td>bapaknya jarang ngajar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3556</th>\n",
       "      <td>1924</td>\n",
       "      <td>positive</td>\n",
       "      <td>belajar sambil jalan2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3557</th>\n",
       "      <td>3119</td>\n",
       "      <td>positive</td>\n",
       "      <td>tidak ada kritikan pak karena bapak mampu memo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3558 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_komentar  sentimen                                           komentar\n",
       "0            1229  negative             kurang memberikan kegunaan dari materi\n",
       "1            1562  negative                terlalu tegas dengan kontrak kuliah\n",
       "2             259  negative                          harus lebih ontime ya pak\n",
       "3            2084  positive  dalam pemaparan materi dan berdiskusi saya sud...\n",
       "4            2674  positive  mampu menggunakan kasus yang terjadi pada kehi...\n",
       "...           ...       ...                                                ...\n",
       "3553         3225  negative  kurang kurangin tugas yang buat kringet dingin...\n",
       "3554          980  negative  terlalu banyak tambahan bobot mata kuliah yang...\n",
       "3555          214  negative                             bapaknya jarang ngajar\n",
       "3556         1924  positive                              belajar sambil jalan2\n",
       "3557         3119  positive  tidak ada kritikan pak karena bapak mampu memo...\n",
       "\n",
       "[3558 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_komentar = pd.read_csv('data/without_neutral_string.csv')\n",
    "coments = data_komentar\n",
    "coments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fungsi untuk Preprocessing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some functions for preprocessing text\n",
    "\n",
    "def cleaningText(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text) # remove mentions\n",
    "    text = re.sub(r'#[A-Za-z0-9]+', '', text) # remove hashtag\n",
    "    text = re.sub(r'RT[\\s]', '', text) # remove RT\n",
    "    text = re.sub(r\"http\\S+\", '', text) # remove link\n",
    "    text = re.sub(r'[0-9]+', '', text) # remove numbers\n",
    "\n",
    "    text = text.replace('\\n', ' ') # replace new line into space\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) # remove all punctuations\n",
    "    text = text.strip(' ') # remove characters space from both left and right text\n",
    "    return text\n",
    "\n",
    "def casefoldingText(text): # Converting all the characters in a text into lower case\n",
    "    text = text.lower() \n",
    "    return text\n",
    "\n",
    "def tokenizingText(text): # Tokenizing or splitting a string, text into a list of tokens\n",
    "    text = word_tokenize(text) \n",
    "    return text\n",
    "\n",
    "def filteringText(text): # Remove stopwors in a text\n",
    "    listStopwords = set(stopwords.words('indonesian'))\n",
    "    exclude_word = set(('tidak', 'bukan', 'kurang', 'belum', 'menyimpang', 'jangan', 'tak', 'tiada', 'engga', 'enggak', 'ndak', 'kagak'))\n",
    "    finalStopword = listStopwords.difference(exclude_word)\n",
    "    filtered = []\n",
    "    for txt in text:\n",
    "        if txt not in finalStopword:\n",
    "            filtered.append(txt)\n",
    "    text = filtered \n",
    "    return text\n",
    "\n",
    "def stemmingText(text): # Reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "    text = [stemmer.stem(word) for word in text]\n",
    "    return text\n",
    "\n",
    "def toSentence(list_words): # Convert list of words into sentence\n",
    "    sentence = ' '.join(word for word in list_words)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  kurang memberikan kegunaan dari materi\n",
       "1                     terlalu tegas dengan kontrak kuliah\n",
       "2                               harus lebih ontime ya pak\n",
       "3       dalam pemaparan materi dan berdiskusi saya sud...\n",
       "4       mampu menggunakan kasus yang terjadi pada kehi...\n",
       "                              ...                        \n",
       "3553    kurang kurangin tugas yang buat kringet dingin...\n",
       "3554    terlalu banyak tambahan bobot mata kuliah yang...\n",
       "3555                               bapaknya jarang ngajar\n",
       "3556                                 belajar sambil jalan\n",
       "3557    tidak ada kritikan pak karena bapak mampu memo...\n",
       "Name: text_clean, Length: 3558, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coments['text_clean'] = coments['komentar'].apply(cleaningText)\n",
    "coments['text_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  kurang memberikan kegunaan dari materi\n",
       "1                     terlalu tegas dengan kontrak kuliah\n",
       "2                               harus lebih ontime ya pak\n",
       "3       dalam pemaparan materi dan berdiskusi saya sud...\n",
       "4       mampu menggunakan kasus yang terjadi pada kehi...\n",
       "                              ...                        \n",
       "3553    kurang kurangin tugas yang buat kringet dingin...\n",
       "3554    terlalu banyak tambahan bobot mata kuliah yang...\n",
       "3555                               bapaknya jarang ngajar\n",
       "3556                                belajar sambil jalan2\n",
       "3557    tidak ada kritikan pak karena bapak mampu memo...\n",
       "Name: text_clean, Length: 3558, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coments['text_clean'] = coments['komentar'].apply(casefoldingText)\n",
    "coments['text_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "coments.drop(['komentar'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            [kurang, memberikan, kegunaan, dari, materi]\n",
       "1               [terlalu, tegas, dengan, kontrak, kuliah]\n",
       "2                         [harus, lebih, ontime, ya, pak]\n",
       "3       [dalam, pemaparan, materi, dan, berdiskusi, sa...\n",
       "4       [mampu, menggunakan, kasus, yang, terjadi, pad...\n",
       "                              ...                        \n",
       "3553    [kurang, kurangin, tugas, yang, buat, kringet,...\n",
       "3554    [terlalu, banyak, tambahan, bobot, mata, kulia...\n",
       "3555                           [bapaknya, jarang, ngajar]\n",
       "3556                            [belajar, sambil, jalan2]\n",
       "3557    [tidak, ada, kritikan, pak, karena, bapak, mam...\n",
       "Name: text_preprocessed, Length: 3558, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coments['text_preprocessed'] = coments['text_clean'].apply(tokenizingText)\n",
    "coments['text_preprocessed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                              [kurang, kegunaan, materi]\n",
       "1                                       [kontrak, kuliah]\n",
       "2                                            [ontime, ya]\n",
       "3       [pemaparan, materi, berdiskusi, senang, mata, ...\n",
       "4                [kehidupan, sehari, rinci, permasalahan]\n",
       "                              ...                        \n",
       "3553      [kurang, kurangin, tugas, kringet, dingin, mis]\n",
       "3554    [tambahan, bobot, mata, kuliah, diinformasikan...\n",
       "3555                           [bapaknya, jarang, ngajar]\n",
       "3556                                    [belajar, jalan2]\n",
       "3557             [tidak, kritikan, memotivasi, mahasiswa]\n",
       "Name: text_preprocessed, Length: 3558, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coments['text_preprocessed'] = coments['text_preprocessed'].apply(filteringText)\n",
    "coments['text_preprocessed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                  [kurang, guna, materi]\n",
       "1                                       [kontrak, kuliah]\n",
       "2                                            [ontime, ya]\n",
       "3       [papar, materi, diskus, senang, mata, kuliah, ...\n",
       "4                           [hidup, hari, rinci, masalah]\n",
       "                              ...                        \n",
       "3553        [kurang, rangin, tugas, kringet, dingin, mis]\n",
       "3554      [tambah, bobot, mata, kuliah, informasi, tidak]\n",
       "3555                              [bapak, jarang, ngajar]\n",
       "3556                                       [ajar, jalan2]\n",
       "3557                 [tidak, kritik, motivasi, mahasiswa]\n",
       "Name: text_preprocessed, Length: 3558, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coments['text_preprocessed'] = coments['text_preprocessed'].apply(stemmingText)\n",
    "coments['text_preprocessed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates/spams tweets\n",
    "coments.drop_duplicates(subset = 'text_clean', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to csv file\n",
    "# coments.to_csv(r'data/coments_data_clean.csv', index = False, header = True,index_label=None)\n",
    "\n",
    "# coments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Visualization\n",
    "\n",
    "## Comparasion Class Sentiment on Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize = (6, 6))\n",
    "sizes = [count for count in coments['sentimen'].value_counts()]\n",
    "labels = list(coments['sentimen'].value_counts().index)\n",
    "explode = (0.01, 0.01)\n",
    "ax.pie(x = sizes, labels = labels, autopct = '%1.1f%%', explode = explode, textprops={'fontsize': 14})\n",
    "ax.set_title('Class Sentiment on Data Komentar \\n', fontsize = 16, pad = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Using LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                      kurang guna materi\n",
       "1                                          kontrak kuliah\n",
       "2                                               ontime ya\n",
       "3       papar materi diskus senang mata kuliah pancasi...\n",
       "4                                hidup hari rinci masalah\n",
       "                              ...                        \n",
       "3553               kurang rangin tugas kringet dingin mis\n",
       "3554             tambah bobot mata kuliah informasi tidak\n",
       "3555                                  bapak jarang ngajar\n",
       "3556                                          ajar jalan2\n",
       "3557                      tidak kritik motivasi mahasiswa\n",
       "Name: text_preprocessed, Length: 3551, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make text preprocessed (tokenized) to untokenized with toSentence Function\n",
    "X = coments['text_preprocessed'].apply(toSentence)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 162, 2],\n",
       " [583, 8],\n",
       " [468, 59],\n",
       " [187, 2, 469, 31, 23, 8, 1065, 98],\n",
       " [39, 322, 470, 236],\n",
       " [85],\n",
       " [64, 13, 29, 222, 60],\n",
       " [31, 109, 1, 56, 34, 584],\n",
       " [21, 1066, 471, 402],\n",
       " [31],\n",
       " [2, 4, 2],\n",
       " [3, 585],\n",
       " [7, 16, 206, 1067, 5],\n",
       " [163, 148, 82, 2, 4, 44, 472],\n",
       " [4, 12, 1],\n",
       " [131, 61],\n",
       " [53, 1],\n",
       " [18, 1068, 35, 18, 59, 20],\n",
       " [35, 65, 734, 11, 19, 4],\n",
       " [1, 10, 4, 14, 735],\n",
       " [2, 23, 8],\n",
       " [1, 85],\n",
       " [188, 1],\n",
       " [3, 110, 164, 68],\n",
       " [1, 3, 99],\n",
       " [13, 62],\n",
       " [48, 2, 16, 9, 69, 32, 2, 1, 68, 66, 10, 20, 12],\n",
       " [70, 3, 9, 2],\n",
       " [76, 36, 1, 4, 1069, 36, 1, 403],\n",
       " [3, 132],\n",
       " [4, 29, 7, 1, 51, 93],\n",
       " [19, 2, 98, 6],\n",
       " [73, 1, 23, 8, 25, 3, 207],\n",
       " [1, 290],\n",
       " [27, 237, 5, 736],\n",
       " [19],\n",
       " [24, 32, 17, 26, 12, 94, 323],\n",
       " [1, 15, 2, 6],\n",
       " [238, 1, 17],\n",
       " [1, 75],\n",
       " [291, 208, 1070, 194, 1071],\n",
       " [1, 13, 239, 586, 36, 36],\n",
       " [61, 1],\n",
       " [3, 195, 11, 8],\n",
       " [3, 143, 258, 1, 292, 4, 6, 72],\n",
       " [13, 587],\n",
       " [165, 3, 41, 1, 2, 8],\n",
       " [95],\n",
       " [67, 473, 19, 5, 3, 9, 2],\n",
       " [7, 293, 294, 14, 11, 11],\n",
       " [26, 324, 7, 7, 196, 474],\n",
       " [13, 86],\n",
       " [67, 1, 19],\n",
       " [4, 1072, 100, 7, 101],\n",
       " [15, 2, 404, 360, 2, 3, 12],\n",
       " [737, 475, 1, 588],\n",
       " [10, 1, 1, 223, 476, 589, 171, 110],\n",
       " [325, 57, 8, 4, 240],\n",
       " [2,\n",
       "  23,\n",
       "  8,\n",
       "  3,\n",
       "  34,\n",
       "  43,\n",
       "  68,\n",
       "  2,\n",
       "  33,\n",
       "  738,\n",
       "  1073,\n",
       "  241,\n",
       "  11,\n",
       "  739,\n",
       "  172,\n",
       "  76,\n",
       "  189,\n",
       "  68,\n",
       "  2],\n",
       " [45, 19, 405, 15, 2],\n",
       " [361, 133],\n",
       " [139, 20, 1074, 24, 24, 114, 2],\n",
       " [21, 7, 12],\n",
       " [31, 1, 77, 109, 16, 173, 206, 109, 29, 477, 5, 258, 39, 1075],\n",
       " [259, 1],\n",
       " [62],\n",
       " [1],\n",
       " [1076, 52],\n",
       " [3, 9, 1, 17, 19, 406, 15],\n",
       " [174, 115, 325, 468],\n",
       " [26, 237],\n",
       " [56, 166, 324, 7, 49],\n",
       " [7, 4, 1, 189, 74, 140, 224, 3, 4, 1077, 140, 7],\n",
       " [478, 1078, 30],\n",
       " [110, 1079, 260, 362, 404, 148],\n",
       " [1, 10],\n",
       " [2],\n",
       " [407, 74, 261],\n",
       " [21, 63, 1, 3, 23, 1, 21, 1],\n",
       " [],\n",
       " [2, 58],\n",
       " [30, 13, 1080, 46],\n",
       " [33, 175, 6, 144, 3, 2, 33, 172, 5, 7, 18, 2, 6],\n",
       " [27, 12],\n",
       " [1081, 408, 13, 1082, 295, 1083, 326],\n",
       " [1, 16, 9, 209, 2, 4, 44, 740, 1084, 210, 2, 68],\n",
       " [78],\n",
       " [2, 1085, 96],\n",
       " [14, 4, 1, 363, 75],\n",
       " [7, 89, 16, 364, 5],\n",
       " [2, 4, 16, 12],\n",
       " [408],\n",
       " [4, 14, 1, 1086, 4, 197],\n",
       " [472, 176, 262],\n",
       " [10, 4, 60, 83, 171],\n",
       " [16, 12, 32, 16, 9],\n",
       " [4, 14, 7, 116, 102, 173, 5, 101, 6, 590],\n",
       " [1087, 1088, 45, 46, 1],\n",
       " [33, 50, 1],\n",
       " [61, 2],\n",
       " [76, 2, 27, 9, 6, 403],\n",
       " [1, 5, 12, 2, 1, 10],\n",
       " [48, 2, 16, 9, 296],\n",
       " [3, 12, 149, 100, 33, 34],\n",
       " [741, 742],\n",
       " [3, 68, 1089, 297, 2, 39, 263],\n",
       " [18, 3, 16, 12],\n",
       " [409,\n",
       "  1090,\n",
       "  743,\n",
       "  111,\n",
       "  1091,\n",
       "  591,\n",
       "  1092,\n",
       "  1093,\n",
       "  1094,\n",
       "  744,\n",
       "  86,\n",
       "  1095,\n",
       "  111,\n",
       "  1096,\n",
       "  744],\n",
       " [14, 7, 22, 3, 1097],\n",
       " [6, 44, 3, 479, 745, 1098],\n",
       " [76, 3, 54, 11, 17, 72],\n",
       " [14, 1, 295, 7, 90, 90, 5, 44, 109, 3, 39, 28, 6],\n",
       " [1099, 8, 43, 33, 34, 120, 117, 34, 190, 11, 177, 242, 4, 18, 2, 96],\n",
       " [26, 264, 298],\n",
       " [4, 14, 365, 365, 480, 236, 17, 149, 5],\n",
       " [18, 2, 17, 58],\n",
       " [36, 8, 30, 410, 8, 4, 197],\n",
       " [10, 8, 16, 12],\n",
       " [1, 123, 10],\n",
       " [4, 64, 746, 72],\n",
       " [45, 3, 106, 6, 5],\n",
       " [1100, 112],\n",
       " [33, 6, 84],\n",
       " [2, 747],\n",
       " [86, 116],\n",
       " [18, 114],\n",
       " [25, 748, 1101, 1, 70],\n",
       " [366, 592, 749, 17, 14, 366, 592, 7, 411],\n",
       " [3, 593],\n",
       " [7, 49, 26, 237],\n",
       " [],\n",
       " [2, 124, 187, 2, 265],\n",
       " [13, 29, 62, 20],\n",
       " [79, 1, 22],\n",
       " [124, 1, 4, 167, 52],\n",
       " [7, 4, 44],\n",
       " [3, 481, 45, 45, 594, 9],\n",
       " [165, 7, 225, 25, 12, 243, 1, 23, 8, 367, 367, 226, 25, 9, 94, 323],\n",
       " [2, 16, 9, 1, 31],\n",
       " [1, 16, 9, 482, 1],\n",
       " [3, 412, 1102, 1, 144],\n",
       " [7, 10],\n",
       " [37, 2, 27, 12, 19, 2],\n",
       " [296],\n",
       " [47, 74, 4, 595, 227],\n",
       " [1, 3, 596, 8, 44],\n",
       " [750, 1, 85, 34, 45, 597, 125, 4, 266],\n",
       " [1],\n",
       " [7, 116],\n",
       " [167, 1, 6],\n",
       " [1, 22, 10],\n",
       " [4, 1, 3, 39, 28],\n",
       " [7, 123, 10, 82, 1103, 123, 1104, 6, 413, 17, 413, 198],\n",
       " [21, 1, 20],\n",
       " [2, 1105, 18, 84, 5, 42, 9, 2],\n",
       " [15, 66, 1, 3, 3, 483, 484, 14, 5, 4, 143, 36, 8, 485],\n",
       " [1106, 598],\n",
       " [3, 3, 103, 66, 1, 56],\n",
       " [3, 228, 2, 8, 5, 4, 486],\n",
       " [4, 36, 8],\n",
       " [3, 61, 1],\n",
       " [3, 12],\n",
       " [4, 20, 487, 599],\n",
       " [1, 27, 12],\n",
       " [37, 488],\n",
       " [131, 414, 5],\n",
       " [267, 4, 143, 50, 126, 5],\n",
       " [4, 11, 24, 4, 143],\n",
       " [1, 155, 155, 415, 268, 600],\n",
       " [91, 6, 13, 244, 293],\n",
       " [416, 2],\n",
       " [601, 47, 92, 20, 13],\n",
       " [1, 10, 5, 12, 2, 1, 368, 1, 103, 602, 327],\n",
       " [1, 1, 10],\n",
       " [751, 87, 259, 1107],\n",
       " [4, 14, 1108, 16, 9],\n",
       " [3],\n",
       " [3, 603, 417, 4, 6],\n",
       " [44, 199, 17, 4, 103, 4],\n",
       " [13, 488, 59, 475],\n",
       " [7, 469, 189, 1],\n",
       " [4, 115, 14, 2, 10],\n",
       " [27, 237, 33, 418, 419, 47, 419, 3, 168],\n",
       " [156],\n",
       " [1109, 328, 1110],\n",
       " [4, 115, 14, 1, 10],\n",
       " [604, 6, 36, 1],\n",
       " [3, 8, 197, 84],\n",
       " [41, 1, 116, 245, 322, 1111],\n",
       " [489, 329, 242, 196, 490, 26, 150, 246, 329, 200, 178],\n",
       " [369, 262],\n",
       " [13, 11, 1112],\n",
       " [37, 7, 4, 1, 4, 71, 1, 2, 4, 5, 4, 143],\n",
       " [60, 28, 6],\n",
       " [1, 80, 229],\n",
       " [29, 1, 2, 4, 44],\n",
       " [33, 50, 6, 5, 413, 141, 1, 22, 140, 7, 22, 64, 413, 330, 413, 55],\n",
       " [752, 30, 168],\n",
       " [82, 3, 103],\n",
       " [753, 753, 5],\n",
       " [2, 145, 51, 93, 27, 12],\n",
       " [2, 52, 54, 420, 45, 247, 25, 5, 157, 45],\n",
       " [4, 71, 84],\n",
       " [1, 77],\n",
       " [86,\n",
       "  64,\n",
       "  22,\n",
       "  331,\n",
       "  111,\n",
       "  158,\n",
       "  10,\n",
       "  29,\n",
       "  754,\n",
       "  248,\n",
       "  32,\n",
       "  88,\n",
       "  7,\n",
       "  249,\n",
       "  269,\n",
       "  32,\n",
       "  92,\n",
       "  86],\n",
       " [1, 3, 1113, 32, 69, 88, 6],\n",
       " [421],\n",
       " [20, 370, 127, 199, 66, 1, 92, 1, 44],\n",
       " [31, 1, 7, 115, 1, 83, 4, 371, 1114, 171],\n",
       " [36,\n",
       "  8,\n",
       "  41,\n",
       "  8,\n",
       "  605,\n",
       "  8,\n",
       "  4,\n",
       "  38,\n",
       "  57,\n",
       "  597,\n",
       "  34,\n",
       "  197,\n",
       "  755,\n",
       "  34,\n",
       "  41,\n",
       "  179,\n",
       "  133,\n",
       "  5,\n",
       "  1115],\n",
       " [3, 96, 63, 210],\n",
       " [134, 14, 250, 135, 1, 15, 121, 12, 21, 63, 1, 59],\n",
       " [162, 51, 93, 18, 2, 25, 12],\n",
       " [211, 12, 414, 5, 146, 20],\n",
       " [3, 9, 5, 9, 25, 2, 1],\n",
       " [14, 4, 7, 78, 1116, 1117, 2],\n",
       " [3, 132, 18, 1118, 23, 8],\n",
       " [756, 372],\n",
       " [210, 164, 17, 176, 4, 3],\n",
       " [3, 12, 1],\n",
       " [65, 20, 2, 113, 201, 24, 94, 26, 1119, 2],\n",
       " [51, 26, 1120],\n",
       " [3, 100, 169, 230, 200],\n",
       " [24, 24, 180, 150, 757, 42],\n",
       " [15, 2, 19],\n",
       " [112],\n",
       " [60, 1, 3, 39, 28, 6, 17, 78],\n",
       " [11, 5, 181],\n",
       " [1, 10, 758],\n",
       " [1, 491, 174, 5, 12],\n",
       " [13, 182, 182, 759],\n",
       " [56, 6, 492],\n",
       " [8, 43, 3, 39],\n",
       " [56, 2, 22, 19],\n",
       " [7, 2, 5],\n",
       " [75, 493, 1121],\n",
       " [33, 1, 196, 1122, 156],\n",
       " [54, 202, 760, 373, 270, 196, 25, 128],\n",
       " [10],\n",
       " [14, 98, 67, 1, 1, 1123, 151, 17, 490, 761, 1124],\n",
       " [3, 12],\n",
       " [7, 87, 1, 416, 762],\n",
       " [56, 98, 172, 1125, 5],\n",
       " [13, 1126, 1, 24, 1127, 110],\n",
       " [18, 15, 51, 25, 5, 12, 494, 93],\n",
       " [2],\n",
       " [45, 3, 763, 1],\n",
       " [10, 104, 5],\n",
       " [3, 1128, 7, 299, 2, 68],\n",
       " [33, 50, 50, 178, 152, 46],\n",
       " [24, 24, 82, 222, 81, 44],\n",
       " [15, 2],\n",
       " [251, 36, 23, 8, 5, 11, 2],\n",
       " [15, 2, 26, 12],\n",
       " [27, 1129, 2, 187],\n",
       " [],\n",
       " [7, 4, 143],\n",
       " [30, 293, 13, 121, 606, 764, 1],\n",
       " [607, 271, 56, 19],\n",
       " [67, 765],\n",
       " [123, 1130, 134, 1131],\n",
       " [66, 1132],\n",
       " [1, 43, 603, 75, 207, 271],\n",
       " [19, 2, 272, 69, 146],\n",
       " [18, 766, 3],\n",
       " [13, 767, 5, 97, 74, 422, 223],\n",
       " [3, 55, 11, 2, 17, 3, 404, 5, 495, 11],\n",
       " [29, 1133, 22, 1, 22, 104, 148, 1134, 332, 768, 56, 212, 333, 22],\n",
       " [18, 37, 27, 12],\n",
       " [7, 87, 16, 206, 5],\n",
       " [24, 180, 769, 11, 1135, 4, 496, 1136],\n",
       " [14, 2, 1137, 4, 55, 109, 8, 8],\n",
       " [423, 608, 1, 609],\n",
       " [133, 266, 1138],\n",
       " [497, 54],\n",
       " [424, 3],\n",
       " [227, 267, 498, 191, 3, 499, 500, 273, 246],\n",
       " [4, 115, 14, 334, 1, 1, 10],\n",
       " [67, 8, 1],\n",
       " [178, 770, 11, 4, 36, 1, 128, 11, 4, 211, 248, 11, 72],\n",
       " [71, 18, 2, 11, 43, 37, 2, 231, 335, 27, 9],\n",
       " [501, 59, 40, 1139, 73, 113, 62, 36],\n",
       " [296],\n",
       " [25, 14, 29, 1, 610, 83, 97, 60],\n",
       " [4, 14, 1, 274, 21, 336],\n",
       " [21, 1, 20],\n",
       " [3, 61, 7],\n",
       " [22, 3],\n",
       " [10, 1, 22, 29],\n",
       " [26, 1140, 1141, 28, 6, 4],\n",
       " [56, 1142, 102, 252, 7],\n",
       " [33, 1, 84],\n",
       " [3, 1143, 5],\n",
       " [3, 6, 84],\n",
       " [3, 1],\n",
       " [7, 163],\n",
       " [187, 2, 10],\n",
       " [2, 275, 425, 1, 112, 129, 63, 25, 374],\n",
       " [18, 19, 5, 27, 58, 12, 2, 1144],\n",
       " [2, 16, 9],\n",
       " [35,\n",
       "  11,\n",
       "  11,\n",
       "  128,\n",
       "  43,\n",
       "  4,\n",
       "  502,\n",
       "  503,\n",
       "  771,\n",
       "  502,\n",
       "  503,\n",
       "  1145,\n",
       "  300,\n",
       "  4,\n",
       "  11,\n",
       "  772,\n",
       "  426,\n",
       "  426,\n",
       "  4,\n",
       "  1],\n",
       " [112, 10, 82, 1146, 2, 504],\n",
       " [48, 11, 95, 9, 2, 134, 11, 65, 427, 44, 84],\n",
       " [53, 18, 15, 2],\n",
       " [3, 9, 18, 2, 24, 50, 504],\n",
       " [30, 5, 13],\n",
       " [11, 375, 112, 27, 6, 169],\n",
       " [9, 1],\n",
       " [45, 118, 773, 505, 506, 72],\n",
       " [248, 11],\n",
       " [2, 1, 7, 9, 767, 5],\n",
       " [29, 73, 1],\n",
       " [507, 267, 15, 2],\n",
       " [7, 35, 4, 1147, 337],\n",
       " [1, 1148],\n",
       " [1, 135, 23, 8],\n",
       " [14, 18, 3, 32],\n",
       " [338, 1149],\n",
       " [2, 3, 276],\n",
       " [4, 236, 7, 48, 8],\n",
       " [79, 774],\n",
       " [49, 19, 9, 49, 69, 134, 70],\n",
       " [201, 1150, 13, 508, 11, 611],\n",
       " [1, 10, 15, 2, 39, 28, 6, 1151],\n",
       " [31, 259, 277, 278],\n",
       " [10],\n",
       " [139, 2],\n",
       " [1, 4, 38],\n",
       " [30,\n",
       "  36,\n",
       "  8,\n",
       "  38,\n",
       "  57,\n",
       "  13,\n",
       "  142,\n",
       "  57,\n",
       "  509,\n",
       "  91,\n",
       "  775,\n",
       "  8,\n",
       "  13,\n",
       "  1152,\n",
       "  339,\n",
       "  1153,\n",
       "  1154,\n",
       "  509,\n",
       "  13,\n",
       "  29,\n",
       "  340,\n",
       "  776,\n",
       "  177,\n",
       "  1155,\n",
       "  242,\n",
       "  1156,\n",
       "  58,\n",
       "  136,\n",
       "  777],\n",
       " [341, 6, 4, 38],\n",
       " [7, 1, 16, 9],\n",
       " [1, 31, 83, 2, 16, 9],\n",
       " [4, 2, 110, 96],\n",
       " [4, 14, 10],\n",
       " [2, 3, 32],\n",
       " [1],\n",
       " [2, 3, 17, 7, 140],\n",
       " [10, 85],\n",
       " [10],\n",
       " [2, 3],\n",
       " [14, 1, 3, 1157, 4, 612, 469],\n",
       " [24, 24, 2, 25, 9],\n",
       " [13, 613, 142, 11, 52, 11, 105, 232, 11, 3, 142, 11, 179, 6, 301, 11, 17, 52],\n",
       " [33, 55, 6],\n",
       " [4, 55, 6],\n",
       " [31, 67, 1, 223, 4, 44, 39, 28, 6],\n",
       " [67, 1],\n",
       " [10, 64, 1],\n",
       " [33, 55, 6],\n",
       " [1, 2],\n",
       " [12, 3, 510, 39, 26],\n",
       " [778, 213, 183],\n",
       " [214, 3, 96],\n",
       " [13, 52, 20],\n",
       " [4, 38, 1158, 4, 779],\n",
       " [45, 106, 780],\n",
       " [1159, 2, 25],\n",
       " [3, 34, 302, 159, 3, 9, 23, 8, 1, 614],\n",
       " [373, 371, 250, 1160],\n",
       " [46, 152, 34, 428, 303, 97, 1, 1161],\n",
       " [35, 7, 57, 17, 258],\n",
       " [2],\n",
       " [131, 1],\n",
       " [2, 5],\n",
       " [3, 304, 47],\n",
       " [1],\n",
       " [215, 2, 4, 19],\n",
       " [28, 6, 60, 8],\n",
       " [1],\n",
       " [7, 12, 233, 5, 189, 38],\n",
       " [1162, 2, 3, 12, 32],\n",
       " [15, 2, 58, 5],\n",
       " [13, 279, 781],\n",
       " [37, 15, 2, 27, 9],\n",
       " [2, 3, 9],\n",
       " [85, 224, 252],\n",
       " [10, 20, 1],\n",
       " [1163, 23, 8, 132, 17, 109],\n",
       " [29],\n",
       " [1],\n",
       " [15, 2, 19, 33, 58, 305, 136, 5],\n",
       " [240, 1, 615],\n",
       " [98],\n",
       " [1, 16, 9, 7, 38, 5, 782],\n",
       " [1, 10],\n",
       " [7, 49, 25, 756, 608, 1164, 245, 202, 46],\n",
       " [7, 4, 26, 160, 5, 74, 88, 11],\n",
       " [1, 18, 274, 237, 2, 121, 192, 5, 6, 4, 12, 18],\n",
       " [10],\n",
       " [4, 10],\n",
       " [3, 101, 15, 2],\n",
       " [1, 70, 75, 24, 511, 29, 1165],\n",
       " [7, 49, 5],\n",
       " [53, 6],\n",
       " [1, 6, 16, 172],\n",
       " [2, 26, 9, 10, 15, 2, 4, 167],\n",
       " [1, 5, 17, 3, 12, 1166, 12],\n",
       " [7, 1167, 14, 25],\n",
       " [1, 42, 5, 42],\n",
       " [1],\n",
       " [6, 38, 57],\n",
       " [42, 371, 11, 128, 5, 216, 1168, 3, 1169],\n",
       " [2, 3, 32, 16, 12],\n",
       " [137, 5, 4, 188, 1],\n",
       " [21, 20, 1, 46, 76, 165, 46, 34, 7, 16, 12, 5, 22],\n",
       " [6, 783, 7, 71, 139, 18, 3],\n",
       " [7, 5],\n",
       " [2, 37, 26, 9],\n",
       " [18, 18, 16, 9],\n",
       " [25, 616, 2],\n",
       " [4, 6],\n",
       " [1, 223, 103],\n",
       " [1, 6, 253, 140],\n",
       " [123, 10],\n",
       " [30, 13, 784, 5, 59, 40],\n",
       " [230, 3, 9, 59, 2, 19, 1170, 1171, 363, 32, 376, 67, 138, 429, 372, 5, 342],\n",
       " [4, 430, 4, 12, 164, 2, 69, 189, 164, 4, 785, 68, 1172],\n",
       " [26, 160, 109, 68],\n",
       " [3, 11, 59, 20],\n",
       " [10, 1, 617, 618, 41],\n",
       " [21, 1, 49],\n",
       " [11, 192, 4, 55, 33, 55, 8],\n",
       " [238, 1, 1173, 10],\n",
       " [45, 34, 3, 106, 377, 8, 192, 495],\n",
       " [431, 254, 4, 38, 512, 619, 786],\n",
       " [],\n",
       " [1, 29, 16, 12, 173, 5, 227, 787],\n",
       " [3, 11, 11, 5, 5, 3, 9, 368, 11],\n",
       " [3, 1174, 144, 788],\n",
       " [1, 2],\n",
       " [2, 32, 263],\n",
       " [11, 3, 1175],\n",
       " [3, 150, 47, 5, 115, 513, 150, 47, 129, 14, 136, 5, 4, 14, 136, 4, 47, 129],\n",
       " [1],\n",
       " [3, 405, 96],\n",
       " [15, 2],\n",
       " [3, 107, 2],\n",
       " [10, 1],\n",
       " [111, 119],\n",
       " [33, 55, 6],\n",
       " [10],\n",
       " [10],\n",
       " [11, 22, 26, 212, 169, 4, 150, 11, 360, 88, 21, 770, 63, 45, 46],\n",
       " [789],\n",
       " [2, 1, 25, 280, 9, 5],\n",
       " [790, 513, 1176, 5],\n",
       " [620, 20, 514, 1, 1177, 1178, 1179, 323, 332],\n",
       " [],\n",
       " [4, 240, 325, 6, 275, 341],\n",
       " [10, 20, 4, 369, 20],\n",
       " [30, 208, 1],\n",
       " [4],\n",
       " [1180, 3, 432],\n",
       " [1181, 8],\n",
       " [748, 1182, 74, 1183, 47, 74, 175, 6, 36, 3, 1184, 14, 15, 2, 27, 9],\n",
       " [1185, 433],\n",
       " [98, 137, 5, 25, 9, 2, 68, 25, 216],\n",
       " [7, 9, 406, 63, 17, 1],\n",
       " [213, 111, 119],\n",
       " [],\n",
       " [1, 96, 306],\n",
       " [2, 13, 203, 343, 515, 10, 343, 18, 2, 25],\n",
       " [1, 791, 7, 1186, 126, 434, 127, 516, 621, 1187, 792, 406, 435],\n",
       " [4, 418, 5, 502, 484],\n",
       " [66, 17, 191, 1188, 160, 63, 17, 100, 422, 17, 4, 9, 1189],\n",
       " [4, 14, 436, 135, 80, 8],\n",
       " [191, 27, 58, 1, 43],\n",
       " [7, 131, 1],\n",
       " [10, 3, 622, 1190, 203],\n",
       " [15, 2, 37, 3],\n",
       " [137, 5, 244, 51, 93, 95, 5, 3, 9],\n",
       " [56, 793],\n",
       " [33, 120, 117, 7],\n",
       " [27, 12],\n",
       " [153],\n",
       " [1],\n",
       " [153, 55, 6, 3],\n",
       " [4, 180, 212, 333, 180, 11],\n",
       " [57, 6, 142],\n",
       " [7, 87],\n",
       " [],\n",
       " [24, 29, 62, 8],\n",
       " [121, 2, 170],\n",
       " [1191, 8, 3],\n",
       " [35, 1192, 50, 6, 91, 6, 623, 2, 210, 230],\n",
       " [30, 1193, 22, 3, 11, 17],\n",
       " [1, 18],\n",
       " [77, 33, 50, 6, 43],\n",
       " [25, 280, 281, 1, 282, 24, 4, 517, 1, 24, 2, 25, 12],\n",
       " [21, 1],\n",
       " [4, 14, 6, 4, 247],\n",
       " [66, 1, 10, 16, 9],\n",
       " [85, 61, 1],\n",
       " [624, 124],\n",
       " [3, 32, 2, 2, 5, 12],\n",
       " [3, 176, 262],\n",
       " [30, 91, 50, 6, 13, 1194, 36, 59, 154, 794, 17, 62, 1195, 21],\n",
       " [2, 200, 625, 16, 9],\n",
       " [1196, 1197],\n",
       " [31],\n",
       " [1, 10],\n",
       " [3, 104, 5, 66, 375, 1198],\n",
       " [10, 2, 26, 12, 42, 297, 2, 189, 35, 18],\n",
       " [1199, 7, 626, 1, 168, 15, 2, 107],\n",
       " [2, 260, 362, 3, 332, 174, 246],\n",
       " [4, 5, 1200, 1201, 229, 21],\n",
       " [1202, 1, 627, 37, 4, 5, 12, 1],\n",
       " [21],\n",
       " [4, 14, 1203, 8, 417, 99, 207],\n",
       " [56, 1204, 5],\n",
       " [795, 369, 518],\n",
       " [4, 247, 193],\n",
       " [31],\n",
       " [24, 164, 1],\n",
       " [1, 6, 10],\n",
       " [1, 1205],\n",
       " [378, 6, 37, 4],\n",
       " [1, 7, 2],\n",
       " [21, 46, 45, 217, 63, 65, 74, 21],\n",
       " [13, 796],\n",
       " [77, 3, 87, 208],\n",
       " [145, 797],\n",
       " [11, 13, 26],\n",
       " [13, 125, 94, 1206, 90],\n",
       " [1, 10, 1, 6, 5, 798, 628, 628],\n",
       " [3, 405, 1207, 2, 629],\n",
       " [1],\n",
       " [7, 101, 1, 479, 630, 138, 479, 344, 129, 74, 631, 7, 5, 204, 6, 101],\n",
       " [201, 113, 154, 16, 37, 4, 110],\n",
       " [62, 156, 17, 36, 632, 633, 1208, 36, 519, 633, 799, 17, 1209, 36, 23, 8],\n",
       " [15, 2, 19],\n",
       " [13, 41],\n",
       " [123, 742, 148],\n",
       " [10, 15, 2],\n",
       " [64, 22, 179, 590, 40, 122, 303, 1210],\n",
       " [18, 3, 3, 16, 9],\n",
       " [520, 1, 283, 800, 800, 4, 173, 424, 138, 150, 480, 80, 1],\n",
       " [7, 87],\n",
       " [98, 1211, 1212, 11, 801, 13, 69, 1213, 345, 138, 1214, 634, 284, 304],\n",
       " [31, 1, 23, 8, 140, 19, 337, 337, 1, 188, 25, 138, 69, 2],\n",
       " [14, 1215, 2, 116],\n",
       " [24, 2, 17, 4, 12],\n",
       " [1],\n",
       " [3],\n",
       " [14, 22, 4, 15, 2, 48, 184, 511, 95, 9, 2],\n",
       " [114, 114, 82, 635, 5, 12, 59, 20],\n",
       " [185, 271, 379, 58, 2],\n",
       " [4, 161],\n",
       " [3, 99, 23, 8],\n",
       " [1, 802, 69, 32, 25, 9, 100, 25, 803, 51, 93],\n",
       " [19, 121, 2],\n",
       " [1216, 1, 45, 46],\n",
       " [10, 2],\n",
       " [35, 7, 36, 8, 38, 57, 8, 120, 117, 43, 5, 791, 7, 21],\n",
       " [24, 26, 1217, 7],\n",
       " [1, 2, 78],\n",
       " [57, 8, 142],\n",
       " [804, 591],\n",
       " [76, 83, 1, 2, 4, 1218],\n",
       " [80, 1, 10],\n",
       " [4, 14, 7, 111, 119],\n",
       " [15, 2, 1219, 23, 8, 521, 96, 18, 3, 70],\n",
       " [10],\n",
       " [21, 63, 66, 1, 1220, 10],\n",
       " [805, 626],\n",
       " [194, 141, 1, 2, 2, 6, 188],\n",
       " [239],\n",
       " [13, 1221],\n",
       " [3, 32, 437],\n",
       " [15, 2, 1, 6],\n",
       " [132, 44, 3, 12, 5, 1222, 1223, 522],\n",
       " [636, 38, 129, 6, 57, 4, 376],\n",
       " [1224],\n",
       " [3, 15, 2],\n",
       " [3, 1225, 6],\n",
       " [123, 10],\n",
       " [2, 1, 12, 5],\n",
       " [1, 7, 2, 5, 1, 12, 2],\n",
       " [37, 1, 44],\n",
       " [1, 2, 5],\n",
       " [14, 1226, 24, 24, 606, 806, 1227, 234],\n",
       " [29, 1, 365, 77, 331, 1228, 158, 69, 11, 149, 38, 2, 1],\n",
       " [140, 62],\n",
       " [4, 14, 7, 23, 8, 121, 2],\n",
       " [1, 3, 31, 27, 12],\n",
       " [2, 30, 1229],\n",
       " [4, 14, 336, 135, 80, 637],\n",
       " [28, 1, 6, 31, 131, 414, 1, 5, 5, 22, 25, 12, 141, 2, 121],\n",
       " [1, 10, 31, 4, 235, 1, 7, 22, 89],\n",
       " [14, 66, 1, 31],\n",
       " [216, 1230, 79, 487, 807, 326, 808, 808, 13, 1231, 21],\n",
       " [69,\n",
       "  23,\n",
       "  8,\n",
       "  3,\n",
       "  161,\n",
       "  68,\n",
       "  2,\n",
       "  5,\n",
       "  4,\n",
       "  34,\n",
       "  120,\n",
       "  117,\n",
       "  43,\n",
       "  68,\n",
       "  2,\n",
       "  241,\n",
       "  11,\n",
       "  809,\n",
       "  11,\n",
       "  810],\n",
       " [204, 638, 5, 1],\n",
       " [2, 24, 24, 3, 12],\n",
       " [15, 2, 26, 9],\n",
       " [65, 1, 26, 12, 5, 28, 1, 3, 4, 23, 8, 152, 50, 235, 11, 11, 811],\n",
       " [18, 82],\n",
       " [65, 20, 19, 26, 9, 22],\n",
       " [20, 487, 213, 10, 1, 149, 639, 639, 1, 260, 362, 1232, 495, 11, 11, 34, 11],\n",
       " [259],\n",
       " [37, 1, 44],\n",
       " [39, 28, 6, 31],\n",
       " [1233, 70, 2, 1234, 145, 27, 9],\n",
       " [1, 4, 261, 131, 2, 8],\n",
       " [5, 135, 299, 1],\n",
       " [2, 471, 37, 4, 38, 32, 2, 640, 307, 1, 51, 307, 5, 37, 42, 73, 151, 8],\n",
       " [1, 10],\n",
       " [39, 28, 8, 92],\n",
       " [41, 641, 519, 345, 6],\n",
       " [1, 63, 4, 181, 1235, 1236, 642, 4, 12, 245, 11, 11, 272, 121, 46],\n",
       " [171],\n",
       " [1237],\n",
       " [35, 4, 62, 8],\n",
       " [3, 812, 1, 70],\n",
       " [15, 2],\n",
       " [1238, 813, 68, 68],\n",
       " [48, 2, 1239, 3, 104, 1, 643, 6, 43, 4, 644],\n",
       " [1, 38, 523, 7],\n",
       " [3, 2],\n",
       " [32, 245, 166, 205, 1240, 438, 45, 42, 524],\n",
       " [1, 16, 160, 2, 1],\n",
       " [3, 39, 28, 6, 40],\n",
       " [11, 26],\n",
       " [35, 98, 5, 128, 2, 425, 425, 304, 202, 4, 5],\n",
       " [15, 2, 10],\n",
       " [56, 23, 8, 17, 120, 117, 339, 1241],\n",
       " [468, 59],\n",
       " [79],\n",
       " [7, 645, 79],\n",
       " [2, 27, 9],\n",
       " [14, 814, 23, 8, 1242, 1243, 4, 308, 814, 334, 2, 63, 38, 284],\n",
       " [2, 346],\n",
       " [95, 130, 494, 93],\n",
       " [7, 172, 12, 5],\n",
       " [2, 16, 12, 16, 9, 87, 815],\n",
       " [2, 17, 1244, 16, 9, 15, 2, 34, 816, 10, 7, 22, 83],\n",
       " [2, 1, 10, 347, 15, 5, 3, 53],\n",
       " [10, 75],\n",
       " [4, 14, 20, 439, 100, 10, 1, 1245, 5, 1, 817],\n",
       " [18, 19],\n",
       " [1246, 774, 380, 1247, 1248, 97, 818, 251, 282],\n",
       " [76, 11, 422, 128],\n",
       " [7, 525, 35, 1249, 1, 6, 8, 478, 1, 1250, 819, 7, 6, 132, 265, 285, 5, 1251],\n",
       " [348, 820, 634, 381, 821, 245, 381, 245, 646, 440, 1252, 134, 1253, 32],\n",
       " [822, 2, 255, 24, 4, 106, 24, 5, 42, 5, 349, 7, 1254, 1255],\n",
       " [104, 5, 74, 3],\n",
       " [4, 14, 1, 9],\n",
       " [382, 4, 6, 84, 4, 102, 7, 6, 75, 11, 190],\n",
       " [194, 1256, 14],\n",
       " [647],\n",
       " [4, 50, 6, 253, 436],\n",
       " [2, 6],\n",
       " [2, 27, 12],\n",
       " [215, 2, 13, 275, 1257, 164, 13, 279, 526],\n",
       " [3, 223, 82],\n",
       " [35, 91, 5, 62, 345, 527],\n",
       " [2, 275, 42],\n",
       " [65, 3, 12],\n",
       " [1258, 2],\n",
       " [1, 16, 12],\n",
       " [3, 218],\n",
       " [56, 34, 46],\n",
       " [2, 27, 25, 9, 823, 7, 25, 84, 504, 326, 21],\n",
       " [61],\n",
       " [47, 11, 11, 3, 1259],\n",
       " [441, 92],\n",
       " [2],\n",
       " [21, 1, 6, 1260, 528, 383, 111, 183, 824, 86],\n",
       " [21, 49, 45, 46, 6, 3],\n",
       " [1],\n",
       " [7, 11, 7, 4, 809, 5, 5, 4, 11, 138, 4],\n",
       " [2, 6, 2, 1261, 51, 384, 3, 9, 51, 93, 470],\n",
       " [7, 10, 12, 5, 8],\n",
       " [10, 148],\n",
       " [199, 13, 1262],\n",
       " [61],\n",
       " [18, 2, 22, 3],\n",
       " [37, 2, 26, 12],\n",
       " [1, 123],\n",
       " [183],\n",
       " [1, 3, 648, 44],\n",
       " [4],\n",
       " [11, 43, 31],\n",
       " [91,\n",
       "  147,\n",
       "  529,\n",
       "  825,\n",
       "  13,\n",
       "  826,\n",
       "  1263,\n",
       "  602,\n",
       "  100,\n",
       "  4,\n",
       "  5,\n",
       "  31,\n",
       "  244,\n",
       "  100,\n",
       "  1264,\n",
       "  385,\n",
       "  17,\n",
       "  648,\n",
       "  530],\n",
       " [14, 147, 4, 7, 1, 131, 58, 649, 136, 5],\n",
       " [1, 10, 16, 9, 347, 97, 120, 117, 26, 827, 227, 1265, 80, 17],\n",
       " [442],\n",
       " [248, 2, 1266, 650, 302, 1267, 1268, 1269, 74],\n",
       " [1, 2, 6, 3],\n",
       " [27, 160, 1],\n",
       " [145, 3, 170],\n",
       " [86, 828, 33, 101, 8, 100, 153, 181, 829, 1270, 830, 22, 86, 828, 86],\n",
       " [4, 175, 34, 120, 117, 6, 43],\n",
       " [1271, 2, 10, 102, 273, 246, 15, 2, 32, 510, 273, 5, 9, 234],\n",
       " [831, 1, 25, 350, 63, 25, 5],\n",
       " [91, 443, 64, 6, 122, 77, 309, 193, 1272, 39, 322, 163, 651, 531],\n",
       " [3, 2, 203, 5],\n",
       " [219, 5],\n",
       " [532, 66, 1, 5, 25, 101],\n",
       " [30, 7, 13, 152, 152, 4, 55, 1273, 23, 8],\n",
       " [2, 3, 12, 5, 15, 2, 3, 3, 106, 652, 5, 160, 3, 9, 1274, 1275, 124, 12, 2],\n",
       " [2, 1, 12],\n",
       " [1276, 182, 40],\n",
       " [178, 3, 364, 5],\n",
       " [60, 82, 29],\n",
       " [33, 55, 1, 188, 2],\n",
       " [7, 11, 1277, 297, 84, 112, 5, 3, 9, 23, 8],\n",
       " [351, 40, 310],\n",
       " [121, 2, 375, 1278],\n",
       " [1, 78, 61, 5],\n",
       " [832, 1, 833, 171],\n",
       " [1, 31],\n",
       " [1, 33],\n",
       " [53, 412, 8, 190, 84, 13, 1279, 57],\n",
       " [91, 64, 13, 60, 59, 20],\n",
       " [26, 172, 7, 49],\n",
       " [1, 19, 2, 272],\n",
       " [10, 92],\n",
       " [11, 192, 39, 26, 249, 95, 94, 17, 174, 92, 1280, 26],\n",
       " [834, 6, 114, 19, 835, 37, 26, 9, 12],\n",
       " [3, 129, 47, 5, 101, 184, 11],\n",
       " [3, 2],\n",
       " [47, 30],\n",
       " [7, 87, 220],\n",
       " [1, 3, 107, 5, 191, 42, 11],\n",
       " [21, 45, 46],\n",
       " [33, 50, 6, 352, 201, 3, 106, 57, 5, 409, 219, 201, 4, 1281, 246],\n",
       " [47, 86, 3, 106, 653, 533, 268, 11, 5, 3, 99],\n",
       " [15, 2, 17, 3],\n",
       " [80, 1, 29, 2, 9, 273, 9],\n",
       " [1, 290],\n",
       " [7, 15, 2],\n",
       " [3, 54, 5],\n",
       " [2, 17, 18],\n",
       " [21, 1, 63, 105, 193],\n",
       " [5, 3, 9, 2],\n",
       " [3, 2, 1282, 1283],\n",
       " [137, 5, 6],\n",
       " [57, 8, 3, 15, 2, 3],\n",
       " [25, 9, 534, 84, 120, 117],\n",
       " [67, 8, 241, 167],\n",
       " [98, 535, 11, 245],\n",
       " [1284, 34, 120, 117, 112, 2, 25, 9, 21],\n",
       " [8, 11, 1285, 52, 157, 129, 500, 5],\n",
       " [813, 32],\n",
       " [3, 18, 2],\n",
       " [1, 16, 9, 2, 89, 119, 7, 836, 46, 178],\n",
       " [1, 5, 19, 536, 5],\n",
       " [146, 20],\n",
       " [18, 2, 16, 9],\n",
       " [15, 2, 265, 53, 5, 9, 17, 1, 2, 19, 5, 27, 9],\n",
       " [617, 6, 53],\n",
       " [138, 274],\n",
       " [88, 144, 1286, 247, 185, 607, 837, 285, 3, 99, 174, 202, 49],\n",
       " [838],\n",
       " [18, 2, 3, 170],\n",
       " [151, 1, 91, 12, 5, 25, 12, 73, 1],\n",
       " [11, 226, 3, 782, 537],\n",
       " [25, 14, 7],\n",
       " [14, 584, 33, 1287],\n",
       " [19, 1],\n",
       " [23, 8, 1288, 7, 87, 16, 206, 5, 1, 22, 508],\n",
       " [1, 110, 839, 3, 12, 162, 51, 93, 1289, 187, 2, 654],\n",
       " [1, 183, 15, 2, 183],\n",
       " [3, 12, 23, 8, 1],\n",
       " [3, 187, 2],\n",
       " [1290, 2],\n",
       " [1291],\n",
       " [153, 7, 22],\n",
       " [290, 1, 1292, 148, 39, 28, 6, 173, 1, 4, 772],\n",
       " [37, 26, 616, 32],\n",
       " [350, 2, 28, 6, 517],\n",
       " [29, 199, 199, 1, 97, 275, 2, 199, 199, 2, 31, 97, 181, 21, 59],\n",
       " [37, 2, 3, 12],\n",
       " [155,\n",
       "  1293,\n",
       "  840,\n",
       "  26,\n",
       "  97,\n",
       "  1,\n",
       "  90,\n",
       "  6,\n",
       "  841,\n",
       "  134,\n",
       "  386,\n",
       "  387,\n",
       "  444,\n",
       "  13,\n",
       "  127,\n",
       "  266,\n",
       "  154,\n",
       "  1294,\n",
       "  123,\n",
       "  141,\n",
       "  380],\n",
       " [48, 11, 42, 842],\n",
       " [3, 211, 41, 5, 5, 5, 337, 337, 75, 156, 4, 41, 342],\n",
       " [1, 16, 12],\n",
       " [1295, 637, 35, 65, 4, 75],\n",
       " [251, 55, 746, 641, 45, 36, 1],\n",
       " [26, 12],\n",
       " [2, 16, 9, 1, 31],\n",
       " [17, 40, 311, 338, 14, 256],\n",
       " [21, 1296, 211, 245, 20, 280],\n",
       " [8, 22, 538, 36, 632, 20, 125, 97, 235, 1, 22],\n",
       " [60, 91, 6, 3, 208, 1297, 219, 843, 186],\n",
       " [6, 611, 7, 4, 844, 2, 5, 24, 4, 7, 2, 4, 255, 3, 2, 5],\n",
       " [20,\n",
       "  311,\n",
       "  82,\n",
       "  123,\n",
       "  10,\n",
       "  3,\n",
       "  29,\n",
       "  80,\n",
       "  158,\n",
       "  129,\n",
       "  353,\n",
       "  829,\n",
       "  94,\n",
       "  353,\n",
       "  92,\n",
       "  1298,\n",
       "  655,\n",
       "  1299,\n",
       "  1300,\n",
       "  1301,\n",
       "  845,\n",
       "  158,\n",
       "  1302],\n",
       " [31, 1, 12, 6, 846, 847, 388, 848, 4, 849, 445],\n",
       " [3, 850],\n",
       " [33, 34, 70, 388, 185, 3, 851, 5],\n",
       " [3, 67, 1, 2],\n",
       " [1, 10, 30, 85, 1, 379, 5, 33, 101, 6, 90, 90, 6, 75, 5, 115, 186],\n",
       " [2, 69, 5],\n",
       " [1303, 28, 6],\n",
       " [1, 10, 193, 273, 11, 38, 2, 17],\n",
       " [1, 10, 124, 7, 7, 490],\n",
       " [24, 2, 783, 22, 4, 221, 139],\n",
       " [170, 18, 15, 2, 3, 39, 28, 6],\n",
       " [91, 179, 133, 639, 1304],\n",
       " [44, 179, 852],\n",
       " [128, 166, 1305, 113],\n",
       " [4, 14],\n",
       " [2, 17, 195, 3],\n",
       " [220, 3, 128, 11, 3, 1306, 90, 90],\n",
       " [3, 9, 19],\n",
       " [853, 35, 481, 216, 656],\n",
       " [35, 16, 854, 855, 27],\n",
       " [232, 1, 2, 470, 5, 354, 9, 2],\n",
       " [1, 15, 2, 10, 5, 16, 12],\n",
       " [105, 22, 303, 97, 1, 6, 303, 428, 446, 184, 332, 10, 657, 658, 3, 6],\n",
       " [1, 86, 172],\n",
       " [1, 3, 29],\n",
       " [4, 186, 172, 1, 10],\n",
       " [],\n",
       " [659, 1, 53],\n",
       " [3, 1307, 6],\n",
       " [3, 22, 54, 41, 191, 247],\n",
       " [24, 3, 405, 15, 2],\n",
       " [76, 8, 80, 71, 1308, 4, 34],\n",
       " [21, 20, 1],\n",
       " [10, 238, 1],\n",
       " [35, 1, 6],\n",
       " [14, 1309, 1310, 225, 130, 856, 1311, 11],\n",
       " [857, 125, 363, 387, 660, 47, 661, 1312, 59, 125, 97, 1313, 92, 447, 662],\n",
       " [3, 16],\n",
       " [82],\n",
       " [11, 1314, 17, 226],\n",
       " [1315, 15, 2, 25, 2, 154, 11, 5, 12, 25, 81],\n",
       " [114, 114, 1316],\n",
       " [48, 54, 17, 72, 3, 5, 42],\n",
       " [47, 1317],\n",
       " [1, 78, 61, 104, 50, 6],\n",
       " [1, 10, 15, 2, 148],\n",
       " [2, 3, 9, 5, 96],\n",
       " [3, 18, 2],\n",
       " [4, 14, 7],\n",
       " [1, 10, 5],\n",
       " [3, 304, 1318, 1319],\n",
       " [11, 30, 13, 192, 4, 858, 448, 11, 1320, 1321],\n",
       " [3, 22, 110, 5, 1, 5, 449, 211, 5, 41, 73, 1, 859, 305],\n",
       " [47, 5, 860],\n",
       " [35, 1322, 861, 14, 251, 55, 13, 539, 34, 30, 5, 4, 134, 203, 1323],\n",
       " [130, 130, 312, 1, 7, 663, 9, 1324, 63, 81, 6, 1325, 1326, 1, 6, 5, 1327],\n",
       " [18, 19, 25, 9],\n",
       " [66, 1, 5, 16, 9, 4, 664, 1, 6],\n",
       " [82, 1328],\n",
       " [4, 14, 2, 67, 1, 161, 6, 43, 10],\n",
       " [30, 95, 5, 4, 12],\n",
       " [862, 1, 1329, 1330],\n",
       " [18, 2, 3, 107, 32, 624, 3, 540],\n",
       " [33, 6, 1],\n",
       " [35, 8, 17],\n",
       " [15, 2, 379, 368, 1331, 11, 11, 313, 5],\n",
       " [56, 1332, 1, 363, 17, 4, 1333],\n",
       " [4, 1, 22, 4, 450],\n",
       " [163],\n",
       " [80, 1334, 13, 167],\n",
       " [236, 15, 54],\n",
       " [37, 5, 410, 665, 76, 36, 330, 45, 36, 330, 6],\n",
       " [4, 20, 439, 111, 119],\n",
       " [1, 3],\n",
       " [1, 6, 75],\n",
       " [7, 17],\n",
       " [30, 13, 127, 863, 20],\n",
       " [604, 6, 1],\n",
       " [119, 7, 1335],\n",
       " [29, 42, 153, 2],\n",
       " [13, 864, 190],\n",
       " [3, 110, 2],\n",
       " [19, 2],\n",
       " [1, 3, 15, 3, 16, 1336, 5],\n",
       " [477, 5],\n",
       " [3, 18],\n",
       " [4, 10],\n",
       " [1, 15, 10, 6],\n",
       " [4, 14, 443, 7, 17, 12, 233, 5, 186, 5, 5, 1337, 29, 23, 8],\n",
       " [24, 91, 2, 865, 1338, 18, 7, 235],\n",
       " [18, 2, 3, 42, 298],\n",
       " [10, 15, 2, 6],\n",
       " [4, 9, 23, 8, 140, 3, 228, 2],\n",
       " [35, 65, 98, 2, 52, 13, 420, 45, 100, 24, 42, 601, 132],\n",
       " [498, 866, 132],\n",
       " [3, 1, 5, 51, 1339],\n",
       " [31],\n",
       " [867, 666, 667, 47],\n",
       " [13, 145, 92],\n",
       " [10, 4, 14],\n",
       " [2, 27, 9, 80, 344, 389, 3, 94, 115, 9, 124],\n",
       " [3, 193, 273, 15, 2],\n",
       " [412, 2],\n",
       " [5, 102, 252, 224, 5],\n",
       " [1340, 114, 92, 20, 125, 12],\n",
       " [70, 3, 9, 2, 11],\n",
       " [35, 54, 4, 1, 153],\n",
       " [1, 44, 3, 648],\n",
       " [10, 1, 6],\n",
       " [1341],\n",
       " [119],\n",
       " [77, 1342, 5, 257, 5, 444, 123, 9, 194, 8, 868, 1343, 3, 9, 8, 125, 9],\n",
       " [30, 98, 274, 27, 9],\n",
       " [328, 328, 17, 328],\n",
       " [869],\n",
       " [25, 102, 5, 180, 390, 6, 586, 668],\n",
       " [96, 870, 22, 286, 203, 355, 541, 132],\n",
       " [33, 6],\n",
       " [15, 2, 27, 12, 2, 145, 3],\n",
       " [1344, 36, 1, 2, 108, 108],\n",
       " [13, 11],\n",
       " [7, 10, 1, 7, 204, 151, 1, 492, 8, 1345],\n",
       " [325, 1346, 10, 1347, 871, 25, 146],\n",
       " [669, 132],\n",
       " [18, 670, 2, 8],\n",
       " [54, 671, 8, 360, 36, 8],\n",
       " [270, 205, 1348, 314],\n",
       " [66, 217, 157, 3, 10],\n",
       " [13, 872, 5, 60],\n",
       " [1349, 9, 13, 665, 25, 12, 188],\n",
       " [56, 64, 46, 391, 229, 12],\n",
       " [3, 12, 2],\n",
       " [1350, 7, 17, 1351],\n",
       " [68, 1, 290, 3, 87, 24, 28, 8, 1352, 256],\n",
       " [1],\n",
       " [183, 672, 873],\n",
       " [348, 17, 4, 38, 542, 542, 8],\n",
       " [1, 23, 8],\n",
       " [3],\n",
       " [874, 293, 115, 86, 662, 1, 86, 1, 1353, 86, 86, 1, 86, 173, 83, 1354],\n",
       " [24, 19, 78, 5, 188, 875, 12, 15, 2, 167, 44, 28, 1, 6, 3, 122],\n",
       " [18, 13, 19],\n",
       " [15, 2, 10],\n",
       " [4, 12, 9, 130, 17, 1],\n",
       " [647],\n",
       " [3, 261, 261],\n",
       " [15, 2, 222, 112, 141],\n",
       " [],\n",
       " [1, 2],\n",
       " [3, 110, 1, 6],\n",
       " [527, 13, 62, 50, 6],\n",
       " [543, 157, 149, 1355, 22, 876, 17, 115, 1356, 1357, 4, 877, 100, 544, 430],\n",
       " [4, 14, 1],\n",
       " [3, 1],\n",
       " [15, 2, 3, 9],\n",
       " [392, 14, 382, 878, 46, 232, 301, 128, 4, 301, 393],\n",
       " [3, 407, 81, 17, 328, 341],\n",
       " [91, 13, 394, 24, 180, 232, 1358, 394],\n",
       " [2, 3, 12, 19],\n",
       " [2, 26, 9],\n",
       " [94, 41, 50],\n",
       " [61, 475],\n",
       " [21, 40, 63],\n",
       " [270, 879, 49, 5, 879],\n",
       " [545, 94, 16, 173, 394, 484, 85, 224, 31],\n",
       " [252, 5, 124, 124, 390, 137, 3, 1, 6, 880, 61, 1],\n",
       " [20, 673, 168, 7, 4, 124, 81, 1359, 3, 1],\n",
       " [146],\n",
       " [67, 1, 314, 116, 28, 1, 101, 1360, 1361, 5, 1362, 67, 1, 1363, 1364],\n",
       " [2, 5],\n",
       " [151,\n",
       "  23,\n",
       "  8,\n",
       "  67,\n",
       "  23,\n",
       "  8,\n",
       "  43,\n",
       "  546,\n",
       "  547,\n",
       "  4,\n",
       "  57,\n",
       "  34,\n",
       "  597,\n",
       "  755,\n",
       "  34,\n",
       "  197,\n",
       "  23,\n",
       "  8,\n",
       "  62,\n",
       "  674],\n",
       " [65, 40, 47, 1365, 47, 307, 662, 402, 21, 40],\n",
       " [372, 429, 675, 675, 1366, 26, 203],\n",
       " [199, 315, 103],\n",
       " [1, 16, 9, 451, 1, 3, 99],\n",
       " [3],\n",
       " [5, 24, 27, 49],\n",
       " [2],\n",
       " [15, 19, 15, 86],\n",
       " [1367, 8],\n",
       " [4, 20, 31, 1],\n",
       " [10, 7, 87],\n",
       " [1368, 152, 22, 1, 548, 22, 64, 89, 651, 4, 60, 12, 17, 109, 1],\n",
       " [22, 3, 15, 2, 19, 26, 9, 50, 6, 22, 361, 356, 268],\n",
       " [3, 15, 2, 52, 5],\n",
       " [1, 22, 1369, 4, 865],\n",
       " [1, 508, 31, 2, 274, 16, 9],\n",
       " [1, 105, 10, 85, 40],\n",
       " [3, 676, 537],\n",
       " [4, 14, 218, 213, 111, 119],\n",
       " [35, 65, 334, 677, 3, 421, 881, 56, 1370, 12, 234, 256],\n",
       " [1371, 1372, 11, 27],\n",
       " [15, 32, 263, 132, 68, 428, 77, 1373, 1374, 351, 857, 97, 141],\n",
       " [21],\n",
       " [77, 33, 55],\n",
       " [45, 1, 120, 117, 43],\n",
       " [290, 62],\n",
       " [518, 5, 4, 96, 69, 69, 1375, 7, 185],\n",
       " [2, 26, 12, 4, 170],\n",
       " [13, 678, 232, 4, 55],\n",
       " [4, 14, 9, 18, 40, 882],\n",
       " [30, 116, 1],\n",
       " [21, 315, 63, 40],\n",
       " [13, 29, 261, 261],\n",
       " [15, 2, 43, 3],\n",
       " [58, 126, 5, 4, 883, 227, 5, 227, 7, 1376, 5, 124],\n",
       " [19, 2],\n",
       " [7, 17, 104, 5],\n",
       " [],\n",
       " [1377, 4],\n",
       " [2, 1, 16, 12, 66, 1, 43, 71, 2, 265],\n",
       " [1, 36, 884, 5, 13, 176, 232, 22, 761],\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features = 5000\n",
    "\n",
    "# Tokenize text with specific maximum number of words to keep, based on word frequency\n",
    "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "tokenizer.fit_on_texts(X.values)\n",
    "\n",
    "X = tokenizer.texts_to_sequences(X.values)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    3,  162,    2],\n",
       "       [   0,    0,    0, ...,    0,  583,    8],\n",
       "       [   0,    0,    0, ...,    0,  468,   59],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,   77,   33,   64],\n",
       "       [   0,    0,    0, ...,    0,    1, 2309],\n",
       "       [   0,    0,    0, ...,   14,  104,    5]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pad_sequences(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3551, 34)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target data into numerical values\n",
    "polarity_encode = {'negative' : 0, 'positive' : 1}\n",
    "y = coments['sentimen'].map(polarity_encode).values\n",
    "\n",
    "# Split the data (with composition data train 80%, data test 20%)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "# print(X_train.shape, y_train.shape)\n",
    "# print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model function with default hyperparameter values\n",
    "\n",
    "def create_model(embed_dim = 16, hidden_unit = 16, dropout_rate = 0.2, optimizers = Adam, learning_rate = 0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim = max_features, output_dim = embed_dim, input_length = X.shape[1]))\n",
    "    model.add(LSTM(units = hidden_unit, activation = 'tanh'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units = 3, activation = 'softmax'))\n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer = optimizers(lr = learning_rate), metrics = ['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>means</th>\n",
       "      <th>stds</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.916513</td>\n",
       "      <td>0.002494</td>\n",
       "      <td>{'batch_size': 128, 'dropout_rate': 0.2, 'embe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.916210</td>\n",
       "      <td>0.012881</td>\n",
       "      <td>{'batch_size': 128, 'dropout_rate': 0.2, 'embe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.915358</td>\n",
       "      <td>0.012066</td>\n",
       "      <td>{'batch_size': 128, 'dropout_rate': 0.2, 'embe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.915012</td>\n",
       "      <td>0.003830</td>\n",
       "      <td>{'batch_size': 128, 'dropout_rate': 0.2, 'embe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.912172</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>{'batch_size': 128, 'dropout_rate': 0.2, 'embe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0.651693</td>\n",
       "      <td>0.007537</td>\n",
       "      <td>{'batch_size': 256, 'dropout_rate': 0.2, 'embe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>0.651693</td>\n",
       "      <td>0.007537</td>\n",
       "      <td>{'batch_size': 256, 'dropout_rate': 0.2, 'embe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>0.651693</td>\n",
       "      <td>0.007537</td>\n",
       "      <td>{'batch_size': 256, 'dropout_rate': 0.2, 'embe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.651693</td>\n",
       "      <td>0.007537</td>\n",
       "      <td>{'batch_size': 256, 'dropout_rate': 0.2, 'embe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>0.651693</td>\n",
       "      <td>0.007537</td>\n",
       "      <td>{'batch_size': 256, 'dropout_rate': 0.2, 'embe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        means      stds                                             params\n",
       "0    0.916513  0.002494  {'batch_size': 128, 'dropout_rate': 0.2, 'embe...\n",
       "1    0.916210  0.012881  {'batch_size': 128, 'dropout_rate': 0.2, 'embe...\n",
       "2    0.915358  0.012066  {'batch_size': 128, 'dropout_rate': 0.2, 'embe...\n",
       "3    0.915012  0.003830  {'batch_size': 128, 'dropout_rate': 0.2, 'embe...\n",
       "4    0.912172  0.008714  {'batch_size': 128, 'dropout_rate': 0.2, 'embe...\n",
       "..        ...       ...                                                ...\n",
       "283  0.651693  0.007537  {'batch_size': 256, 'dropout_rate': 0.2, 'embe...\n",
       "284  0.651693  0.007537  {'batch_size': 256, 'dropout_rate': 0.2, 'embe...\n",
       "285  0.651693  0.007537  {'batch_size': 256, 'dropout_rate': 0.2, 'embe...\n",
       "286  0.651693  0.007537  {'batch_size': 256, 'dropout_rate': 0.2, 'embe...\n",
       "287  0.651693  0.007537  {'batch_size': 256, 'dropout_rate': 0.2, 'embe...\n",
       "\n",
       "[288 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results from hyperparameter tuning\n",
    "results = pd.read_csv('data/gridsearchcv_results.csv')\n",
    "results.sort_values(by='means', ascending = False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model with the best hyperparameter which has been determined\n",
    "model = KerasClassifier(build_fn = create_model,\n",
    "                        # Model Parameters\n",
    "                        dropout_rate = 0.2,\n",
    "                        embed_dim = 32,\n",
    "                        hidden_unit = 16,\n",
    "                        optimizers = RMSprop,\n",
    "                        learning_rate = 0.001,\n",
    "                   \n",
    "                        # Fit Parameters\n",
    "                        epochs=10, \n",
    "                        batch_size=128,\n",
    "                        # Initiate validation data, which is 10% data from data train. It's used for evaluation model\n",
    "                        validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring1 = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "            'precision': make_scorer(precision_score, average='macro'),\n",
    "            'recall': make_scorer(recall_score, average='macro'),\n",
    "            'f1': make_scorer(f1_score, average='macro')\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 34, 32)            160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 16)                3136      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 163,187\n",
      "Trainable params: 163,187\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fury\\Anaconda3\\envs\\myenviroment\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2556 samples, validate on 284 samples\n",
      "Epoch 1/10\n",
      "2556/2556 [==============================] - 1s 308us/step - loss: 0.9172 - accuracy: 0.5739 - val_loss: 0.7453 - val_accuracy: 0.5775\n",
      "Epoch 2/10\n",
      "2556/2556 [==============================] - 0s 161us/step - loss: 0.7245 - accuracy: 0.5743 - val_loss: 0.6973 - val_accuracy: 0.5775\n",
      "Epoch 3/10\n",
      "2556/2556 [==============================] - 0s 160us/step - loss: 0.6888 - accuracy: 0.5982 - val_loss: 0.6689 - val_accuracy: 0.5775\n",
      "Epoch 4/10\n",
      "2556/2556 [==============================] - 0s 155us/step - loss: 0.6399 - accuracy: 0.6604 - val_loss: 0.6149 - val_accuracy: 0.7077\n",
      "Epoch 5/10\n",
      "2556/2556 [==============================] - 0s 154us/step - loss: 0.5564 - accuracy: 0.7938 - val_loss: 0.5493 - val_accuracy: 0.7570\n",
      "Epoch 6/10\n",
      "2556/2556 [==============================] - 0s 154us/step - loss: 0.4730 - accuracy: 0.8451 - val_loss: 0.4810 - val_accuracy: 0.8099\n",
      "Epoch 7/10\n",
      "2556/2556 [==============================] - 0s 151us/step - loss: 0.4057 - accuracy: 0.8693 - val_loss: 0.4396 - val_accuracy: 0.8239\n",
      "Epoch 8/10\n",
      "2556/2556 [==============================] - 0s 152us/step - loss: 0.3528 - accuracy: 0.8948 - val_loss: 0.4049 - val_accuracy: 0.8239\n",
      "Epoch 9/10\n",
      "2556/2556 [==============================] - 0s 148us/step - loss: 0.3166 - accuracy: 0.9030 - val_loss: 0.3960 - val_accuracy: 0.8380\n",
      "Epoch 10/10\n",
      "2556/2556 [==============================] - 0s 149us/step - loss: 0.2893 - accuracy: 0.9057 - val_loss: 0.3710 - val_accuracy: 0.8380\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 34, 32)            160000    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 16)                3136      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 163,187\n",
      "Trainable params: 163,187\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fury\\Anaconda3\\envs\\myenviroment\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2556 samples, validate on 285 samples\n",
      "Epoch 1/10\n",
      "2556/2556 [==============================] - 1s 312us/step - loss: 0.9695 - accuracy: 0.5591 - val_loss: 0.8198 - val_accuracy: 0.5754\n",
      "Epoch 2/10\n",
      "2556/2556 [==============================] - 0s 162us/step - loss: 0.7603 - accuracy: 0.5865 - val_loss: 0.7026 - val_accuracy: 0.5754\n",
      "Epoch 3/10\n",
      "2556/2556 [==============================] - 0s 153us/step - loss: 0.6609 - accuracy: 0.6252 - val_loss: 0.6418 - val_accuracy: 0.5789\n",
      "Epoch 4/10\n",
      "2556/2556 [==============================] - 0s 146us/step - loss: 0.5710 - accuracy: 0.7418 - val_loss: 0.5642 - val_accuracy: 0.8211\n",
      "Epoch 5/10\n",
      "2556/2556 [==============================] - 0s 141us/step - loss: 0.4967 - accuracy: 0.8204 - val_loss: 0.4887 - val_accuracy: 0.8316\n",
      "Epoch 6/10\n",
      "2556/2556 [==============================] - 0s 142us/step - loss: 0.4285 - accuracy: 0.8541 - val_loss: 0.4510 - val_accuracy: 0.8421\n",
      "Epoch 7/10\n",
      "2556/2556 [==============================] - 0s 143us/step - loss: 0.3679 - accuracy: 0.8822 - val_loss: 0.4040 - val_accuracy: 0.8456\n",
      "Epoch 8/10\n",
      "2556/2556 [==============================] - 0s 141us/step - loss: 0.3271 - accuracy: 0.8940 - val_loss: 0.3798 - val_accuracy: 0.8386\n",
      "Epoch 9/10\n",
      "2556/2556 [==============================] - 0s 140us/step - loss: 0.2938 - accuracy: 0.9038 - val_loss: 0.3549 - val_accuracy: 0.8561\n",
      "Epoch 10/10\n",
      "2556/2556 [==============================] - 0s 144us/step - loss: 0.2614 - accuracy: 0.9120 - val_loss: 0.3555 - val_accuracy: 0.8596\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 34, 32)            160000    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 16)                3136      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 163,187\n",
      "Trainable params: 163,187\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fury\\Anaconda3\\envs\\myenviroment\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2556 samples, validate on 285 samples\n",
      "Epoch 1/10\n",
      "2556/2556 [==============================] - 1s 295us/step - loss: 0.9362 - accuracy: 0.5540 - val_loss: 0.7656 - val_accuracy: 0.5754\n",
      "Epoch 2/10\n",
      "2556/2556 [==============================] - 0s 144us/step - loss: 0.7439 - accuracy: 0.5755 - val_loss: 0.7084 - val_accuracy: 0.5754\n",
      "Epoch 3/10\n",
      "2556/2556 [==============================] - 0s 141us/step - loss: 0.7021 - accuracy: 0.5935 - val_loss: 0.6775 - val_accuracy: 0.5754\n",
      "Epoch 4/10\n",
      "2556/2556 [==============================] - 0s 143us/step - loss: 0.6623 - accuracy: 0.6440 - val_loss: 0.6387 - val_accuracy: 0.7579\n",
      "Epoch 5/10\n",
      "2556/2556 [==============================] - 0s 141us/step - loss: 0.5885 - accuracy: 0.7570 - val_loss: 0.5662 - val_accuracy: 0.7789\n",
      "Epoch 6/10\n",
      "2556/2556 [==============================] - 0s 143us/step - loss: 0.5022 - accuracy: 0.8306 - val_loss: 0.5196 - val_accuracy: 0.7614\n",
      "Epoch 7/10\n",
      "2556/2556 [==============================] - 0s 142us/step - loss: 0.4299 - accuracy: 0.8611 - val_loss: 0.4454 - val_accuracy: 0.8105\n",
      "Epoch 8/10\n",
      "2556/2556 [==============================] - 0s 140us/step - loss: 0.3668 - accuracy: 0.8807 - val_loss: 0.4056 - val_accuracy: 0.8211\n",
      "Epoch 9/10\n",
      "2556/2556 [==============================] - 0s 144us/step - loss: 0.3220 - accuracy: 0.8998 - val_loss: 0.3989 - val_accuracy: 0.8281\n",
      "Epoch 10/10\n",
      "2556/2556 [==============================] - 0s 141us/step - loss: 0.2886 - accuracy: 0.9077 - val_loss: 0.3569 - val_accuracy: 0.8351\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 34, 32)            160000    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 16)                3136      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 163,187\n",
      "Trainable params: 163,187\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fury\\Anaconda3\\envs\\myenviroment\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2556 samples, validate on 285 samples\n",
      "Epoch 1/10\n",
      "2556/2556 [==============================] - 1s 302us/step - loss: 0.9929 - accuracy: 0.5896 - val_loss: 0.8232 - val_accuracy: 0.6877\n",
      "Epoch 2/10\n",
      "2556/2556 [==============================] - 0s 162us/step - loss: 0.7223 - accuracy: 0.6514 - val_loss: 0.6464 - val_accuracy: 0.6561\n",
      "Epoch 3/10\n",
      "2556/2556 [==============================] - 0s 162us/step - loss: 0.5868 - accuracy: 0.7351 - val_loss: 0.5602 - val_accuracy: 0.8035\n",
      "Epoch 4/10\n",
      "2556/2556 [==============================] - 0s 163us/step - loss: 0.5281 - accuracy: 0.7696 - val_loss: 0.5320 - val_accuracy: 0.7509\n",
      "Epoch 5/10\n",
      "2556/2556 [==============================] - 0s 160us/step - loss: 0.4524 - accuracy: 0.8157 - val_loss: 0.4732 - val_accuracy: 0.8140\n",
      "Epoch 6/10\n",
      "2556/2556 [==============================] - 0s 162us/step - loss: 0.3964 - accuracy: 0.8502 - val_loss: 0.4288 - val_accuracy: 0.8246\n",
      "Epoch 7/10\n",
      "2556/2556 [==============================] - 0s 147us/step - loss: 0.3433 - accuracy: 0.8838 - val_loss: 0.3961 - val_accuracy: 0.8316\n",
      "Epoch 8/10\n",
      "2556/2556 [==============================] - 0s 154us/step - loss: 0.3163 - accuracy: 0.8951 - val_loss: 0.4124 - val_accuracy: 0.8281\n",
      "Epoch 9/10\n",
      "2556/2556 [==============================] - 0s 152us/step - loss: 0.2782 - accuracy: 0.9108 - val_loss: 0.3617 - val_accuracy: 0.8351\n",
      "Epoch 10/10\n",
      "2556/2556 [==============================] - 0s 145us/step - loss: 0.2524 - accuracy: 0.9159 - val_loss: 0.3554 - val_accuracy: 0.8421\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 34, 32)            160000    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 16)                3136      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 163,187\n",
      "Trainable params: 163,187\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fury\\Anaconda3\\envs\\myenviroment\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2556 samples, validate on 285 samples\n",
      "Epoch 1/10\n",
      "2556/2556 [==============================] - 1s 321us/step - loss: 0.9675 - accuracy: 0.5689 - val_loss: 0.8065 - val_accuracy: 0.5930\n",
      "Epoch 2/10\n",
      "2556/2556 [==============================] - 0s 157us/step - loss: 0.7855 - accuracy: 0.5720 - val_loss: 0.7269 - val_accuracy: 0.5930\n",
      "Epoch 3/10\n",
      "2556/2556 [==============================] - 0s 151us/step - loss: 0.7194 - accuracy: 0.5978 - val_loss: 0.6730 - val_accuracy: 0.6070\n",
      "Epoch 4/10\n",
      "2556/2556 [==============================] - 0s 151us/step - loss: 0.6455 - accuracy: 0.6952 - val_loss: 0.6130 - val_accuracy: 0.6421\n",
      "Epoch 5/10\n",
      "2556/2556 [==============================] - 0s 152us/step - loss: 0.5679 - accuracy: 0.7746 - val_loss: 0.5443 - val_accuracy: 0.8070\n",
      "Epoch 6/10\n",
      "2556/2556 [==============================] - 0s 152us/step - loss: 0.5068 - accuracy: 0.8099 - val_loss: 0.5204 - val_accuracy: 0.8105\n",
      "Epoch 7/10\n",
      "2556/2556 [==============================] - 0s 153us/step - loss: 0.4386 - accuracy: 0.8490 - val_loss: 0.4640 - val_accuracy: 0.7895\n",
      "Epoch 8/10\n",
      "2556/2556 [==============================] - 0s 154us/step - loss: 0.3911 - accuracy: 0.8764 - val_loss: 0.4254 - val_accuracy: 0.8070\n",
      "Epoch 9/10\n",
      "2556/2556 [==============================] - 0s 155us/step - loss: 0.3440 - accuracy: 0.8979 - val_loss: 0.3803 - val_accuracy: 0.8491\n",
      "Epoch 10/10\n",
      "2556/2556 [==============================] - 0s 154us/step - loss: 0.3160 - accuracy: 0.8998 - val_loss: 0.3596 - val_accuracy: 0.8456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([5.47554779, 5.19342065, 5.15275574, 5.38170552, 5.55536294]),\n",
       " 'score_time': array([0.15199924, 0.15399361, 0.15200686, 0.154001  , 0.15006733]),\n",
       " 'test_accuracy': array([0.88748242, 0.86760563, 0.8943662 , 0.86197183, 0.86760563]),\n",
       " 'test_precision': array([0.88200335, 0.86344538, 0.89015698, 0.8587384 , 0.86567286]),\n",
       " 'test_recall': array([0.8921268 , 0.8766328 , 0.89139797, 0.86403562, 0.86301603]),\n",
       " 'test_f1': array([0.88516515, 0.86554006, 0.89076004, 0.86037197, 0.86422707])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cv_score = cross_validate(model, X, y, cv=5, scoring=scoring)\n",
    "cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 34, 32)            160000    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 16)                3136      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 163,187\n",
      "Trainable params: 163,187\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fury\\Anaconda3\\envs\\myenviroment\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2556 samples, validate on 284 samples\n",
      "Epoch 1/10\n",
      "2556/2556 [==============================] - 1s 299us/step - loss: 0.9369 - accuracy: 0.4746 - val_loss: 0.7695 - val_accuracy: 0.6549\n",
      "Epoch 2/10\n",
      "2556/2556 [==============================] - 0s 154us/step - loss: 0.7391 - accuracy: 0.5806 - val_loss: 0.6926 - val_accuracy: 0.5775\n",
      "Epoch 3/10\n",
      "2556/2556 [==============================] - 0s 147us/step - loss: 0.6714 - accuracy: 0.6545 - val_loss: 0.6372 - val_accuracy: 0.6972\n",
      "Epoch 4/10\n",
      "2556/2556 [==============================] - 0s 149us/step - loss: 0.6020 - accuracy: 0.7238 - val_loss: 0.5762 - val_accuracy: 0.7676\n",
      "Epoch 5/10\n",
      "2556/2556 [==============================] - 0s 148us/step - loss: 0.5248 - accuracy: 0.7856 - val_loss: 0.5155 - val_accuracy: 0.7782\n",
      "Epoch 6/10\n",
      "2556/2556 [==============================] - 0s 144us/step - loss: 0.4484 - accuracy: 0.8353 - val_loss: 0.4635 - val_accuracy: 0.8169\n",
      "Epoch 7/10\n",
      "2556/2556 [==============================] - 0s 144us/step - loss: 0.3752 - accuracy: 0.8705 - val_loss: 0.4216 - val_accuracy: 0.8380\n",
      "Epoch 8/10\n",
      "2556/2556 [==============================] - 0s 145us/step - loss: 0.3158 - accuracy: 0.8916 - val_loss: 0.3868 - val_accuracy: 0.8310\n",
      "Epoch 9/10\n",
      "2556/2556 [==============================] - 0s 145us/step - loss: 0.2699 - accuracy: 0.9143 - val_loss: 0.3631 - val_accuracy: 0.8451\n",
      "Epoch 10/10\n",
      "2556/2556 [==============================] - 0s 146us/step - loss: 0.2442 - accuracy: 0.9174 - val_loss: 0.3467 - val_accuracy: 0.8662\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 34, 32)            160000    \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 16)                3136      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 163,187\n",
      "Trainable params: 163,187\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fury\\Anaconda3\\envs\\myenviroment\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2556 samples, validate on 285 samples\n",
      "Epoch 1/10\n",
      "2556/2556 [==============================] - 1s 285us/step - loss: 0.9814 - accuracy: 0.5591 - val_loss: 0.8055 - val_accuracy: 0.5754\n",
      "Epoch 2/10\n",
      "2556/2556 [==============================] - 0s 148us/step - loss: 0.7595 - accuracy: 0.5779 - val_loss: 0.7136 - val_accuracy: 0.5754\n",
      "Epoch 3/10\n",
      "2556/2556 [==============================] - 0s 147us/step - loss: 0.7151 - accuracy: 0.5806 - val_loss: 0.6819 - val_accuracy: 0.5754\n",
      "Epoch 4/10\n",
      "2556/2556 [==============================] - 0s 147us/step - loss: 0.6652 - accuracy: 0.6330 - val_loss: 0.6258 - val_accuracy: 0.7404\n",
      "Epoch 5/10\n",
      "2556/2556 [==============================] - 0s 145us/step - loss: 0.5771 - accuracy: 0.7606 - val_loss: 0.5475 - val_accuracy: 0.7719\n",
      "Epoch 6/10\n",
      "2556/2556 [==============================] - 0s 148us/step - loss: 0.4827 - accuracy: 0.8177 - val_loss: 0.4793 - val_accuracy: 0.7860\n",
      "Epoch 7/10\n",
      "2556/2556 [==============================] - 0s 148us/step - loss: 0.3974 - accuracy: 0.8619 - val_loss: 0.4311 - val_accuracy: 0.8140\n",
      "Epoch 8/10\n",
      "2556/2556 [==============================] - 0s 146us/step - loss: 0.3346 - accuracy: 0.8881 - val_loss: 0.4273 - val_accuracy: 0.8105\n",
      "Epoch 9/10\n",
      "2556/2556 [==============================] - 0s 144us/step - loss: 0.2936 - accuracy: 0.9045 - val_loss: 0.3619 - val_accuracy: 0.8456\n",
      "Epoch 10/10\n",
      "2556/2556 [==============================] - 0s 144us/step - loss: 0.2681 - accuracy: 0.9131 - val_loss: 0.3496 - val_accuracy: 0.8667\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 34, 32)            160000    \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 16)                3136      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 163,187\n",
      "Trainable params: 163,187\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fury\\Anaconda3\\envs\\myenviroment\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2556 samples, validate on 285 samples\n",
      "Epoch 1/10\n",
      "2556/2556 [==============================] - 1s 310us/step - loss: 1.0001 - accuracy: 0.5849 - val_loss: 0.8210 - val_accuracy: 0.5754\n",
      "Epoch 2/10\n",
      "2556/2556 [==============================] - 0s 159us/step - loss: 0.7310 - accuracy: 0.6264 - val_loss: 0.6700 - val_accuracy: 0.5754\n",
      "Epoch 3/10\n",
      "2556/2556 [==============================] - 0s 158us/step - loss: 0.6197 - accuracy: 0.7136 - val_loss: 0.5668 - val_accuracy: 0.7895\n",
      "Epoch 4/10\n",
      "2556/2556 [==============================] - 0s 152us/step - loss: 0.5068 - accuracy: 0.7954 - val_loss: 0.4900 - val_accuracy: 0.8105\n",
      "Epoch 5/10\n",
      "2556/2556 [==============================] - 0s 154us/step - loss: 0.4243 - accuracy: 0.8470 - val_loss: 0.4307 - val_accuracy: 0.8211\n",
      "Epoch 6/10\n",
      "2556/2556 [==============================] - 0s 153us/step - loss: 0.3631 - accuracy: 0.8764 - val_loss: 0.4070 - val_accuracy: 0.8491\n",
      "Epoch 7/10\n",
      "2556/2556 [==============================] - 0s 154us/step - loss: 0.3101 - accuracy: 0.9034 - val_loss: 0.4034 - val_accuracy: 0.8211\n",
      "Epoch 8/10\n",
      "2556/2556 [==============================] - 0s 156us/step - loss: 0.2684 - accuracy: 0.9045 - val_loss: 0.3503 - val_accuracy: 0.8561\n",
      "Epoch 9/10\n",
      "2556/2556 [==============================] - 0s 154us/step - loss: 0.2319 - accuracy: 0.9186 - val_loss: 0.3457 - val_accuracy: 0.8351\n",
      "Epoch 10/10\n",
      "2556/2556 [==============================] - 0s 150us/step - loss: 0.2179 - accuracy: 0.9225 - val_loss: 0.3271 - val_accuracy: 0.8702\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 34, 32)            160000    \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 16)                3136      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 163,187\n",
      "Trainable params: 163,187\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fury\\Anaconda3\\envs\\myenviroment\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2556 samples, validate on 285 samples\n",
      "Epoch 1/10\n",
      "2556/2556 [==============================] - 1s 302us/step - loss: 0.9239 - accuracy: 0.5732 - val_loss: 0.7567 - val_accuracy: 0.5754\n",
      "Epoch 2/10\n",
      "2556/2556 [==============================] - 0s 157us/step - loss: 0.7128 - accuracy: 0.6041 - val_loss: 0.6805 - val_accuracy: 0.6246\n",
      "Epoch 3/10\n",
      "2556/2556 [==============================] - 0s 158us/step - loss: 0.6411 - accuracy: 0.6635 - val_loss: 0.6054 - val_accuracy: 0.6877\n",
      "Epoch 4/10\n",
      "2556/2556 [==============================] - 0s 155us/step - loss: 0.5503 - accuracy: 0.7743 - val_loss: 0.5248 - val_accuracy: 0.8175\n",
      "Epoch 5/10\n",
      "2556/2556 [==============================] - 0s 155us/step - loss: 0.4560 - accuracy: 0.8455 - val_loss: 0.4589 - val_accuracy: 0.8246\n",
      "Epoch 6/10\n",
      "2556/2556 [==============================] - 0s 146us/step - loss: 0.3806 - accuracy: 0.8873 - val_loss: 0.4220 - val_accuracy: 0.8316\n",
      "Epoch 7/10\n",
      "2556/2556 [==============================] - 0s 148us/step - loss: 0.3232 - accuracy: 0.8998 - val_loss: 0.3831 - val_accuracy: 0.8281\n",
      "Epoch 8/10\n",
      "2556/2556 [==============================] - 0s 147us/step - loss: 0.2756 - accuracy: 0.9202 - val_loss: 0.3634 - val_accuracy: 0.8421\n",
      "Epoch 9/10\n",
      "2556/2556 [==============================] - 0s 147us/step - loss: 0.2504 - accuracy: 0.9253 - val_loss: 0.3467 - val_accuracy: 0.8491\n",
      "Epoch 10/10\n",
      "2556/2556 [==============================] - 0s 147us/step - loss: 0.2168 - accuracy: 0.9343 - val_loss: 0.3410 - val_accuracy: 0.8561\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 34, 32)            160000    \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 16)                3136      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 163,187\n",
      "Trainable params: 163,187\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fury\\Anaconda3\\envs\\myenviroment\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2556 samples, validate on 285 samples\n",
      "Epoch 1/10\n",
      "2556/2556 [==============================] - 1s 289us/step - loss: 0.9616 - accuracy: 0.5634 - val_loss: 0.7641 - val_accuracy: 0.5930\n",
      "Epoch 2/10\n",
      "2556/2556 [==============================] - 0s 144us/step - loss: 0.7526 - accuracy: 0.5599 - val_loss: 0.6987 - val_accuracy: 0.5930\n",
      "Epoch 3/10\n",
      "2556/2556 [==============================] - 0s 144us/step - loss: 0.6939 - accuracy: 0.6283 - val_loss: 0.6401 - val_accuracy: 0.6807\n",
      "Epoch 4/10\n",
      "2556/2556 [==============================] - 0s 147us/step - loss: 0.6012 - accuracy: 0.7387 - val_loss: 0.5640 - val_accuracy: 0.7649\n",
      "Epoch 5/10\n",
      "2556/2556 [==============================] - 0s 145us/step - loss: 0.5199 - accuracy: 0.8001 - val_loss: 0.5159 - val_accuracy: 0.8316\n",
      "Epoch 6/10\n",
      "2556/2556 [==============================] - 0s 143us/step - loss: 0.4523 - accuracy: 0.8435 - val_loss: 0.4436 - val_accuracy: 0.8246\n",
      "Epoch 7/10\n",
      "2556/2556 [==============================] - 0s 140us/step - loss: 0.3869 - accuracy: 0.8772 - val_loss: 0.4032 - val_accuracy: 0.8421\n",
      "Epoch 8/10\n",
      "2556/2556 [==============================] - 0s 142us/step - loss: 0.3448 - accuracy: 0.8834 - val_loss: 0.3842 - val_accuracy: 0.8596\n",
      "Epoch 9/10\n",
      "2556/2556 [==============================] - 0s 143us/step - loss: 0.3089 - accuracy: 0.9057 - val_loss: 0.3569 - val_accuracy: 0.8667\n",
      "Epoch 10/10\n",
      "2556/2556 [==============================] - 0s 147us/step - loss: 0.2653 - accuracy: 0.9159 - val_loss: 0.3430 - val_accuracy: 0.8632\n",
      "Accuracy Score 0.8811602365530836\n",
      "Precision Score 0.8768052928216593\n",
      "Recall Score 0.8794675533805969\n",
      "F1 Score 0.8780285271499546\n"
     ]
    }
   ],
   "source": [
    "cv_pred = cross_val_predict(model, X, y, cv=5)\n",
    "print(\"Accuracy Score\",accuracy_score(y, cv_pred))\n",
    "print(\"Precision Score\",precision_score(y, cv_pred, average='macro'))\n",
    "print(\"Recall Score\",recall_score(y, cv_pred, average='macro'))\n",
    "print(\"F1 Score\",f1_score(y, cv_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy each fold : [0.88748242 0.86760563 0.8943662  0.86197183 0.86760563]\n",
      "Precision each fold : [0.88200335 0.86344538 0.89015698 0.8587384  0.86567286]\n",
      "Recall each fold : [0.8921268  0.8766328  0.89139797 0.86403562 0.86301603]\n",
      "F1 each fold : [0.88516515 0.86554006 0.89076004 0.86037197 0.86422707]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy each fold :\", cv_score['test_accuracy'])\n",
    "print(\"Precision each fold :\", cv_score['test_precision'])\n",
    "print(\"Recall each fold :\", cv_score['test_recall'])\n",
    "print(\"F1 each fold :\", cv_score['test_f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1849,  230],\n",
       "       [ 192, 1280]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(y, cv_pred)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average : 0.8758063429805272\n",
      "Precision average : 0.872003394698577\n",
      "Recall average : 0.877441844750668\n",
      "F1 average : 0.8732128557272055\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy average :\", cv_score['test_accuracy'].mean())\n",
    "print(\"Precision average :\", cv_score['test_precision'].mean())\n",
    "print(\"Recall average :\", cv_score['test_recall'].mean())\n",
    "print(\"F1 average :\", cv_score['test_f1'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation of Accuracy is 0.014201196484679119 \n",
      "Standard Deviation of Precision is 0.0134054754215675 \n",
      "Standard Deviation of Recall is 0.014132470266935728 \n",
      "Standard Deviation of F1 is 0.013741049099543046 \n"
     ]
    }
   ],
   "source": [
    "print(\"Standard Deviation of Accuracy is % s \" % (statistics.stdev(cv_score['test_accuracy'])))\n",
    "print(\"Standard Deviation of Precision is % s \" % (statistics.stdev(cv_score['test_precision'])))\n",
    "print(\"Standard Deviation of Recall is % s \" % (statistics.stdev(cv_score['test_recall'])))\n",
    "print(\"Standard Deviation of F1 is % s \" % (statistics.stdev(cv_score['test_f1'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
